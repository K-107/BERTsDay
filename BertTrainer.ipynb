{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BertTrainer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1tjMLTE_Xe8cK2Sc3DBYMxIHp33ZKMVQF",
      "authorship_tag": "ABX9TyMNVUbeEccLojKB3pipBOEf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/K-107/BERTsDay/blob/main/BertTrainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_YJBC7mYH92"
      },
      "source": [
        "### 사전 작업"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAiLYBm0AJFC"
      },
      "source": [
        "# GPU 정보 보기\n",
        "! nvidia-smi --query | fgrep 'Product Name'"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUn97HspAMmB",
        "outputId": "677f7f45-cc4f-4b06-8367-6c7ec38539af"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqr_RupN9eCR",
        "outputId": "27b791e0-7606-45a8-e4e6-a198d76b6389"
      },
      "source": [
        "# 리포지토리 복제\n",
        "%cd /content/\n",
        "! git clone https://github.com/K-107/BERTsDay.git"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'BERTsDay'...\n",
            "remote: Enumerating objects: 119, done.\u001b[K\n",
            "remote: Counting objects: 100% (119/119), done.\u001b[K\n",
            "remote: Compressing objects: 100% (93/93), done.\u001b[K\n",
            "remote: Total 119 (delta 36), reused 70 (delta 16), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (119/119), 57.40 KiB | 2.30 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnh1Cm8HFYLt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "250803b2-bf1d-424e-83fe-0005a5cb571e"
      },
      "source": [
        "# 밑의 모듈은 텐서플로 1.x로 작성되었으므로 버전 변경\n",
        "! pip install --upgrade tensorflow==1.15.0rc3"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow==1.15.0rc3 in /usr/local/lib/python3.7/dist-packages (1.15.0rc3)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (1.15.1)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.0rc3) (54.2.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc3) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc3) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0rc3) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc3) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc3) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc3) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5bMIHUOIbEt"
      },
      "source": [
        "## pretrained BERT 모델을 모듈로 export\n",
        "\n",
        "ETRI에서 사전훈련한 BERT의 체크포인트를 가지고 BERT 모듈을 만드는 과정."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeIaHvuVAHQz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a164a844-6d53-460f-a092-e4bdd57d15c2"
      },
      "source": [
        "! if [ ! -d /content/drive/MyDrive/bert_slottagging/ ]; then echo \"프리트레인 모듈화 진행중\"; python /content/BERTsDay/Bert_fine_tuning/export_korbert/bert_to_module.py -i \"/content/drive/MyDrive/bert_slottagging/004_bert_eojeol_tensorflow\" -o \"/content/drive/MyDrive/bert_slottagging/Bert_pretrained/\"; echo\"완료\"; else echo \"프리트레인 모듈화 이미 완료됨\"; fi"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "프리트레인 모듈화 이미 완료됨\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKjPC4RLIW52"
      },
      "source": [
        "## 데이터 준비\n",
        "\n",
        "모델을 훈련하기 위해 필요한 seq.in, seq.out이라는 2가지 파일을 만드는 과정.\n",
        "\n",
        "**(중요) 사전에 프로젝트 폴더 아래에 sample이란 폴더가 있어야 하며, sample_input.txt 파일이 있어야 합니다.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j-r72rOZtOs",
        "outputId": "d207f463-3e37-4e74-8a87-ee34a7571e50"
      },
      "source": [
        "%cd /content/drive/MyDrive/bert_slottagging\n",
        "! if [ -d ./sample ]; then echo \"sample 폴더 존재\"; else echo \"sample 폴더가 만들어졌습니다, sample 폴더에 sample_input.txt파일을 넣어주세요\"; mkdir \"./sample\"; fi\n",
        "%cd /content/drive/MyDrive/bert_slottagging/sample"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/bert_slottagging\n",
            "sample 폴더 존재\n",
            "/content/drive/MyDrive/bert_slottagging/sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK7B70fE0U_V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d727754-a2cb-4a77-8bff-b3b79503927e"
      },
      "source": [
        "#1. 텍스트 파일의 문장들을 무작위로 뒤섞는 명령어\n",
        "!shuf sample_input.txt > temp_0.txt\n",
        "# 2. 공백 문자 여러개를 하나로 줄이는 명령어\n",
        "! sed 's/  */ /g' temp_0.txt > temp_1.txt\n",
        "#3. 앞, 뒤의 공백 문자를 없애는 명렁어\n",
        "#앞 :\n",
        "! sed 's/^ //g' temp_1.txt > temp_2.txt\n",
        "#뒤 :\n",
        "! sed 's/ $//g' temp_2.txt > temp_3.txt\n",
        "#4. 중복 제거하는 명령어\n",
        "! sort -u temp_3.txt > sample_output.txt\n",
        "# 임시 파일들 제거\n",
        "! rm temp_0.txt\n",
        "! rm temp_1.txt\n",
        "! rm temp_2.txt\n",
        "! rm temp_3.txt"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1706704896 bytes == 0x55a4b797a000 @  0x7f5a78a481e7 0x55a4b513a718 0x55a4b51395a1 0x7f5a78426bf7 0x55a4b513a02a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD19IkPSiDcc"
      },
      "source": [
        "! head -123 sample_output.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvJiIykZ00aJ",
        "outputId": "eec37734-cd7f-4d65-acf3-02fb5d24d8f0"
      },
      "source": [
        "# 문장 갯수 세고, 파일 쪼개기\n",
        "sentence_count = !wc -l sample_output.txt | grep -o \"[0-9]*\"\n",
        "sentence_count = int(sentence_count[0])\n",
        "train_count = int(sentence_count*0.6)\n",
        "test_count = int(sentence_count*0.2)\n",
        "val_count = sentence_count - train_count - test_count\n",
        "\n",
        "!echo \"전체 문장 개수: $sentence_count, 훈련: $train_count, 테스트: $test_count, 검증: $val_count\"\n",
        "!split -l $train_count sample_output.txt sample_\n",
        "!mv \"sample_aa\" train.txt\n",
        "!head -n $val_count sample_ab > val.txt\n",
        "!tail -n $test_count sample_ab > test.txt\n",
        "!rm sample_ab"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 문장: 995363, 훈련: 597217, 테스트: 199072, 검증: 199074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "318K89xn7QIw",
        "outputId": "c51e2e15-73a6-4e62-d2de-2e66d8dcadd5"
      },
      "source": [
        "# 쪼갠 파일을 각각의 폴더에 seq.in, seq.out으로 저장\n",
        "! for file in \"train.txt\" \"test.txt\" \"val.txt\"; do if [ -f $file ]; then folder=`echo $file | cut -f 1 -d '.'`; if [ ! -d \"$folder\" ]; then mkdir \"$folder\"; echo \"$folder 폴더 생성\"; fi; echo \"$folder 데이터 준비중\"; python /content/BERTsDay/Bert_fine_tuning/prepare_data.py -i \"$file\" -o \"$PWD/$folder\" -vp \"/content/drive/MyDrive/bert_slottagging/Bert_pretrained/assets/vocab.korean.rawtext.list\"; echo \"완료\"; else echo \"파일 $file 없음\"; fi; done"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 데이터 준비중\n",
            "WARNING:tensorflow:From /content/BERTsDay/Bert_fine_tuning/to_array/tokenizationK.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "완료\n",
            "test 폴더 생성\n",
            "test 데이터 준비중\n",
            "WARNING:tensorflow:From /content/BERTsDay/Bert_fine_tuning/to_array/tokenizationK.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "완료\n",
            "val 폴더 생성\n",
            "val 데이터 준비중\n",
            "WARNING:tensorflow:From /content/BERTsDay/Bert_fine_tuning/to_array/tokenizationK.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "완료\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RFAnVoM0Uqe"
      },
      "source": [
        "### Fine-tuing 훈련\n",
        "\n",
        "어떻게 하면 train_bert_finetuning.py 코드를 실행할 수 있는지 코드 내부의 parser을 참조하여 작성하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltH99gSK1Gel",
        "outputId": "273339db-c890-401d-fc59-260f717dc11e"
      },
      "source": [
        "%cd /content/drive/MyDrive/bert_slottagging/\n",
        "! python /content/BERTsDay/Bert_fine_tuning/train_bert_finetuning.py -bp \"./Bert_pretrained/\" -t \"./sample/train/\" -v \"./sample/val/\" -s \"./Fine_tuned/\" -e 3 -bs 256 -tp bert"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/bert_slottagging\n",
            "WARNING:tensorflow:From /content/BERTsDay/Bert_fine_tuning/train_bert_finetuning.py:44: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2021-04-15 06:00:53.282174: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-04-15 06:00:53.292070: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200155000 Hz\n",
            "2021-04-15 06:00:53.292543: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557c02efe840 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-04-15 06:00:53.292594: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-04-15 06:00:53.311900: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-15 06:00:53.362439: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-04-15 06:00:53.362538: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ed9cd5ddb468): /proc/driver/nvidia/version does not exist\n",
            "read data ...\n",
            "train_text_arr[0:2] : ['빈_ 방_ 예 약_', '빈_ 방_ 예 약_ 돼_']\n",
            "train_tags_arr[0:2] : ['O O O O', 'O O O O O']\n",
            "initializing!\n",
            "is_bert : True\n",
            "WARNING:tensorflow:From /content/BERTsDay/Bert_fine_tuning/to_array/tokenizationK.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "initialized!\n",
            "bert toarray started ...\n",
            "transform started\n",
            "vectorize tags ...\n",
            "train_tags : [[1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0.]]\n",
            "slot num : 8 ['<PAD>' 'O' '날짜' '번호' '시작시간' '이름' '인원' '종료시간']\n",
            "bert inputs : [<tf.Tensor 'input_ids:0' shape=(?, ?) dtype=int32>, <tf.Tensor 'input_mask:0' shape=(?, ?) dtype=int32>, <tf.Tensor 'segment_ids:0' shape=(?, ?) dtype=int32>]\n",
            "init ok\n",
            "call ok\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "slots output : (?, ?, 8)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "KorBertLayer (KorBertLayer)     (None, None, 768)    109693440   input_ids[0][0]                  \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 8)      6152        KorBertLayer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 109,699,592\n",
            "Trainable params: 70,884,872\n",
            "Non-trainable params: 38,814,720\n",
            "__________________________________________________________________________________________________\n",
            "train input shape : (597217, 53) [[   2 2899 1336  223  623    3    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]\n",
            " [   2 2899 1336  223  623  529    3    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0]]\n",
            "train_input_mask : (597217, 53) [[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "train_segment_ids : (597217, 53) [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "train_tags : (597217, 53) [[1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0.]]\n",
            "preparing validation data\n",
            "transform started\n",
            "training model ...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 597217 samples, validate on 199074 samples\n",
            "Epoch 1/3\n",
            "2021-04-15 06:03:55.740847: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 166723584 exceeds 10% of system memory.\n",
            "2021-04-15 06:03:57.426490: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 166723584 exceeds 10% of system memory.\n",
            "2021-04-15 06:03:57.426490: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 166723584 exceeds 10% of system memory.\n",
            "2021-04-15 06:03:57.490488: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 166723584 exceeds 10% of system memory.\n",
            "2021-04-15 06:04:00.202749: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 166723584 exceeds 10% of system memory.\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1ndD9dn2FlU"
      },
      "source": [
        "## 모델 평가\n",
        "\n",
        "TODO - 위의 내용처럼 어떻게 하면 eval_bert_finetuned.py 코드를 실행할 수 있는지 코드 내부의 parser을 참조하여 작성하세요.\n",
        "테스트의 결과는 --model에 넣어준 모델 경로 아래의 test_results에 저장된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CM7LuAD2HEK"
      },
      "source": [
        "%cd /content/drive/MyDrive/bert_slottagging/\n",
        "! python /content/BERTsDay/Bert_fine_tuning/eval_bert_finetuned.py -bp \"./Bert_pretrained/\" -t bert -m \"./Fine_tuned/\" -d \"./sample/test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twFK8y4v2I0F"
      },
      "source": [
        "## Inference (임의의 문장을 모델에 넣어보기)\n",
        "\n",
        "TODO - eval_bert_finetuned.py를 참고하여 한 문장씩 넣어서 모델이 내뱉는 결과물을 볼 수 있도록 inference.py 코드를 완성하세요.  \n",
        "python inference.py --model {훈련된 모델이 저장된 경로}  \n",
        "예시: python inference.py --model saved_model/  \n",
        "모델 자체가 용량이 커서 불러오는 데까지 시간이 걸림  \n",
        "\"Enter your sentence:\"라는 문구가 나오면 모델에 넣어보고 싶은 문장을 넣어 주면 됨  \n",
        "quit라는 입력을 넣어 주면 종료  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRNjDviv2ImB"
      },
      "source": [
        "%cd /content/drive/MyDrive/bert_slottagging/\n",
        "!python /content/BERTsDay/Bert_fine_tuning/inference.py -bp \"./Bert_pretrained/\" -m \"./Fine_tuned/\" -tp bert"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}