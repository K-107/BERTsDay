{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BertTrainer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1tjMLTE_Xe8cK2Sc3DBYMxIHp33ZKMVQF",
      "authorship_tag": "ABX9TyMn1fdkIsKaVjOhb9ejZT2I",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/K-107/BERTsDay/blob/main/BertTrainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAiLYBm0AJFC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5838ecbd-0e9c-48f1-f18c-8fc0d0f766e4"
      },
      "source": [
        "# GPU 정보 보기\n",
        "! nvidia-smi --query | fgrep 'Product Name'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Product Name                          : Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUn97HspAMmB",
        "outputId": "0fc3e14c-7c4c-407c-a557-3cb91e0a3759"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqr_RupN9eCR",
        "outputId": "ce009d4a-d398-478d-f901-f38622570b09"
      },
      "source": [
        "# 리포지토리 복제\n",
        "! git clone https://github.com/K-107/BERTsDay.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'BERTsDay' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wnh1Cm8HFYLt",
        "outputId": "be955408-74b9-481a-d3b0-b483fa9790dd"
      },
      "source": [
        "# 밑의 모듈은 텐서플로 1.x로 작성되었으므로 버전 변경\n",
        "! pip install --upgrade tensorflow==1.15.0rc3"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow==1.15.0rc3 in /usr/local/lib/python3.7/dist-packages (1.15.0rc3)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (1.15.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0rc3) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc3) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc3) (54.2.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc3) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0rc3) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc3) (3.8.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc3) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0rc3) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5bMIHUOIbEt"
      },
      "source": [
        "## pretrained BERT 모델을 모듈로 export\n",
        "\n",
        "ETRI에서 사전훈련한 BERT의 체크포인트를 가지고 BERT 모듈을 만드는 과정."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeIaHvuVAHQz"
      },
      "source": [
        "! python /content/BERTsDay/Bert_fine_tuning/export_korbert/bert_to_module.py -i \"/content/drive/MyDrive/3_Slot_Tagging_Proj/004_bert_eojeol_tensorflow\" -o \"/content/drive/MyDrive/3_Slot_Tagging_Proj\""
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKjPC4RLIW52"
      },
      "source": [
        "## 데이터 준비\n",
        "\n",
        "모델을 훈련하기 위해 필요한 seq.in, seq.out이라는 2가지 파일을 만드는 과정.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUvxSgyfKjlx",
        "outputId": "6c12bc80-57b5-4cec-a94e-736960f604a5"
      },
      "source": [
        "%cd /content/drive/MyDrive/3_Slot_Tagging_Proj/\n",
        "#!python make_data.py train_data.txt > train_data.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/3_Slot_Tagging_Proj\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK7B70fE0U_V"
      },
      "source": [
        "#1. 텍스트 파일에서 랜덤한 문장만 추출하는 명령어\n",
        "!shuf -n 1280000 ./output_sample2.txt > ./sample/temp_0.txt"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLKKh7I40eiS"
      },
      "source": [
        "# 2. 공백 문자 여러개를 하나로 줄이는 명령어\n",
        "! sed 's/  */ /g' ./sample/temp_0.txt > ./sample/temp_1.txt"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJhi-Vg40ygx"
      },
      "source": [
        "#3. 앞, 뒤의 공백 문자를 없애는 명렁어\n",
        "#앞 :\n",
        "! sed 's/^ //g' ./sample/temp_1.txt > ./sample/temp_2.txt\n",
        "#뒤 :\n",
        "! sed 's/ $//g' ./sample/temp_2.txt > ./sample/temp_3.txt"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvJiIykZ00aJ",
        "outputId": "7b629074-354d-4a8e-a5eb-e9ef72b831f9"
      },
      "source": [
        "#4. 중복 제거하는 명령어 (두 가지 방법 모두 동일합니다.)\n",
        "! sort -u ./sample/sample_3.txt > ./sample/sample_1M.txt\n",
        "\n",
        "# 임시 파일들 제거\n",
        "! rm ./sample/temp_0.txt\n",
        "! rm ./sample/temp_1.txt\n",
        "! rm ./sample/temp_2.txt\n",
        "! rm ./sample/temp_3.txt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1706696704 bytes == 0x55bf1d954000 @  0x7fb2873a41e7 0x55bf1b40f718 0x55bf1b40e5a1 0x7fb286d82bf7 0x55bf1b40f02a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao7gL5mBIS4B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb9e863f-ec7c-49ac-bb8c-01d88b9d8d97"
      },
      "source": [
        "# 실행 전에 소스 수정 필요함\n",
        "! python /content/BERTsDay/Bert_fine_tuning/prepare_data.py -i ./sample/sample_1M.txt -o ./sample/"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/BERTsDay/Bert_fine_tuning/to_array/tokenizationK.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RFAnVoM0Uqe"
      },
      "source": [
        "### Fine-tuing 훈련\n",
        "\n",
        "어떻게 하면 train_bert_finetuning.py 코드를 실행할 수 있는지 코드 내부의 parser을 참조하여 작성하세요.\n",
        "  \n",
        "그리고 소스 파일 내에서 bert 모델의 경로를 고치세요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltH99gSK1Gel",
        "outputId": "dadbd49c-3ed4-418d-bce2-eab0b4daf967"
      },
      "source": [
        "# 실행 전에 소스 수정 필요함\n",
        "! python /content/BERTsDay/Bert_fine_tuning/train_bert_finetuning.py -t \"./sample/\" -s ./fine_tuned -e 10000 -bs 128 -tp bert"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/BERTsDay/Bert_fine_tuning/train_bert_finetuning.py:41: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2021-04-12 07:43:20.840381: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-04-12 07:43:20.845775: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-04-12 07:43:20.845981: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c35a60680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-04-12 07:43:20.846011: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-04-12 07:43:20.847842: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-12 07:43:20.959477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-12 07:43:20.960311: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564c35a60f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-04-12 07:43:20.960349: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2021-04-12 07:43:20.960521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-12 07:43:20.961088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-04-12 07:43:20.961631: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-04-12 07:43:20.965206: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-04-12 07:43:20.967816: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-04-12 07:43:20.969280: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-04-12 07:43:20.973549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-04-12 07:43:20.975843: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-04-12 07:43:20.982321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-04-12 07:43:20.982434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-12 07:43:20.983010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-12 07:43:20.983521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2021-04-12 07:43:20.983580: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-04-12 07:43:20.984799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-04-12 07:43:20.984828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2021-04-12 07:43:20.984838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2021-04-12 07:43:20.984960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-12 07:43:20.985527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-12 07:43:20.986053: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-04-12 07:43:20.986091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "read data ...\n",
            "train_text_arr[0:2] : ['0 시_ 에서_ 10 시_ 까지_ 김 민주 ᆫ _ 이름 으로_ 총_ 10 명_ 에서_ 날 짜 는_ 10월_ 10일_ 빈_ 거_ 예 약_', '0 시_ 부터_ 10 시_ 까지_ 총_ 10 명_ 에서_ 날 짜 는_ 10월_ 10일_ 김 민주 ᆫ _ 이름 으로_ 빈_ 거_ 예 약_']\n",
            "train_tags_arr[0:2] : ['시작시간 시작시간 O 종료시간 종료시간 O 이름 이름 이름 이름 O O O 인원 인원 O O O O 날짜 날짜 O O O O', '시작시간 시작시간 O 종료시간 종료시간 O O 인원 인원 O O O O 날짜 날짜 이름 이름 이름 이름 O O O O O O']\n",
            "initializing!\n",
            "is_bert : True\n",
            "WARNING:tensorflow:From /content/BERTsDay/Bert_fine_tuning/to_array/tokenizationK.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "initialized!\n",
            "bert toarray started ...\n",
            "transform started\n",
            "vectorize tags ...\n",
            "/content/BERTsDay/Bert_fine_tuning/to_array/tags_to_array.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  data = np.array(data)\n",
            "train_tags : [[1. 3. 3. 1. 6. 6. 1. 4. 4. 4. 4. 1. 1. 1. 5. 5. 1. 1. 1. 1. 2. 2. 1. 1.\n",
            "  1. 1. 1. 0.]\n",
            " [1. 3. 3. 1. 6. 6. 1. 1. 5. 5. 1. 1. 1. 1. 2. 2. 4. 4. 4. 4. 1. 1. 1. 1.\n",
            "  1. 1. 1. 0.]]\n",
            "slot num : 7 ['<PAD>' 'O' '날짜' '시작시간' '이름' '인원' '종료시간']\n",
            "bert inputs : [<tf.Tensor 'input_ids:0' shape=(?, ?) dtype=int32>, <tf.Tensor 'input_mask:0' shape=(?, ?) dtype=int32>, <tf.Tensor 'segment_ids:0' shape=(?, ?) dtype=int32>]\n",
            "init ok\n",
            "call ok\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "slots output : (?, ?, 7)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "KorBertLayer (KorBertLayer)     (None, None, 768)    109693440   input_ids[0][0]                  \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 7)      5383        KorBertLayer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 109,698,823\n",
            "Trainable params: 70,884,103\n",
            "Non-trainable params: 38,814,720\n",
            "__________________________________________________________________________________________________\n",
            "train input shape : (1277958, 28) [[    2   296   228    22   220   228   167   120   919 16007     9  1110\n",
            "     31  1122   220   563    22   439  1902    21  1347  2186  2899  1206\n",
            "    223   623     3     0]\n",
            " [    2   296   228   397   220   228   167  1122   220   563    22   439\n",
            "   1902    21  1347  2186   120   919 16007     9  1110    31  2899  1206\n",
            "    223   623     3     0]]\n",
            "train_input_mask : (1277958, 28) [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
            " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]]\n",
            "train_segment_ids : (1277958, 28) [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "train_tags : (1277958, 28) [[1. 3. 3. 1. 6. 6. 1. 4. 4. 4. 4. 1. 1. 1. 5. 5. 1. 1. 1. 1. 2. 2. 1. 1.\n",
            "  1. 1. 1. 0.]\n",
            " [1. 3. 3. 1. 6. 6. 1. 1. 5. 5. 1. 1. 1. 1. 2. 2. 4. 4. 4. 4. 1. 1. 1. 1.\n",
            "  1. 1. 1. 0.]]\n",
            "training model ...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 1277958 samples\n",
            "Epoch 1/10000\n",
            "2021-04-12 07:46:30.161844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            " 454656/1277958 [=========>....................] - ETA: 34:44 - loss: 0.0017 - sparse_categorical_crossentropy: 0.0017"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1ndD9dn2FlU"
      },
      "source": [
        "## 모델 평가\n",
        "\n",
        "TODO - 위의 내용처럼 어떻게 하면 eval_bert_finetuned.py 코드를 실행할 수 있는지 코드 내부의 parser을 참조하여 작성하세요.\n",
        "테스트의 결과는 --model에 넣어준 모델 경로 아래의 test_results에 저장된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CM7LuAD2HEK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twFK8y4v2I0F"
      },
      "source": [
        "## Inference (임의의 문장을 모델에 넣어보기)\n",
        "\n",
        "TODO - eval_bert_finetuned.py를 참고하여 한 문장씩 넣어서 모델이 내뱉는 결과물을 볼 수 있도록 inference.py 코드를 완성하세요.  \n",
        "python inference.py --model {훈련된 모델이 저장된 경로}  \n",
        "예시: python inference.py --model saved_model/  \n",
        "모델 자체가 용량이 커서 불러오는 데까지 시간이 걸림  \n",
        "\"Enter your sentence:\"라는 문구가 나오면 모델에 넣어보고 싶은 문장을 넣어 주면 됨  \n",
        "quit라는 입력을 넣어 주면 종료  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRNjDviv2ImB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}